{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "from meld.recon import UnrolledNetwork\n",
    "from meld.util import getAbs, getPhase\n",
    "from meld.model import pytorch_proximal\n",
    "\n",
    "import h5py\n",
    "import mri\n",
    "import model\n",
    "import dataloader\n",
    "import lib_complex as cp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device_no = 2\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "torch.cuda.set_device(device_no)\n",
    "device = torch.device(\"cuda:\"+str(device_no) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np_dtype = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Volumes into slabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: ['imgs', 'ksp', 'maps']\n",
      "number of data points: 16\n",
      "0\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "1\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "2\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "3\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "4\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "5\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "6\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "7\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "8\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "9\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "10\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "11\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "12\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "13\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "14\n",
      "(8, 320, 256, 320) (320, 256, 320)\n",
      "15\n",
      "(8, 320, 256, 320) (320, 256, 320)\n"
     ]
    }
   ],
   "source": [
    "total_size = 320\n",
    "slab_size = 50\n",
    "\n",
    "# path to file containing imgs, k-space, and map data\n",
    "datapath = \"/mikQNAP/dataset_train_knees_3d.h5\"\n",
    "# datapath = \"/mikQNAP/dataset_test_knees_3d.h5\"\n",
    "\n",
    "cropped_maps = []\n",
    "cropped_imgs = []\n",
    "\n",
    "with h5py.File(datapath, 'r') as F:\n",
    "    print('keys:', list(F.keys()))\n",
    "    length = len(F['imgs'])\n",
    "    print('number of data points:', length)\n",
    "    for ii in range(length):        \n",
    "        print(ii)\n",
    "#         print(F['maps'][ii,...].shape)\n",
    "        maps = np.transpose(np.array(F['maps'][ii,...], dtype=np.complex), axes=(1,0,2,3))\n",
    "        imgs = np.transpose(np.array(F['imgs'][ii,...], dtype=np.complex), axes=(0,1,2))\n",
    "#         imgs = np.array(F['maps'][ii,...], dtype=np.complex)\n",
    "#         maps = np.swapaxes(np.array(F['maps'][ii,...], dtype=np.complex), 1, 2)\n",
    "#         imgs = np.swapaxes(np.array(F['imgs'][ii,...], dtype=np.complex), 0, 1)\n",
    "        print(maps.shape, imgs.shape)\n",
    "        for jj in range(np.int(np.floor(total_size/slab_size))):\n",
    "            start_idx = jj*slab_size\n",
    "            end_idx = (jj+1)*slab_size\n",
    "            maps_tmp = maps[:,start_idx:end_idx,...]\n",
    "            imgs_tmp = imgs[start_idx:end_idx,...]\n",
    "            cropped_imgs.append(imgs_tmp)\n",
    "            cropped_maps.append(maps_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 256, 320)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(cropped_imgs))\n",
    "new_imgs = np.array(cropped_imgs)\n",
    "new_maps = np.array(cropped_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_maps_file = h5py.File(\"/tmp/kellman/3d_dataset_maps_50.h5\", \"w\")\n",
    "new_maps_file['maps'] = new_maps\n",
    "new_maps_file.flush()\n",
    "new_maps_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_file = h5py.File(\"/tmp/kellman/3d_dataset_imgs_50.h5\", \"w\")\n",
    "new_imgs_file['imgs'] = new_imgs\n",
    "new_imgs_file.flush()\n",
    "new_imgs_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sampling masks\n",
    "From /mikRAID/frank/data/cube_knees/fully_sampled <br>\n",
    "the code below splits the masks into different h5 files for training/testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dir = '/mikRAID/frank/data/cube_knees/train_mask_slices/'\n",
    "masks = []\n",
    "total = new_imgs.shape[0]\n",
    "c = 0\n",
    "for mask in os.listdir(masks_dir):\n",
    "    if mask.split('.')[1] == 'npy':\n",
    "        if c <= total-1:\n",
    "            c += 1\n",
    "            continue\n",
    "        masks.append(np.load(masks_dir + mask))\n",
    "        c += 1\n",
    "        if c > total - 1 + total:\n",
    "            break\n",
    "\n",
    "masks_array = np.array(masks)\n",
    "masks_array = np.fft.fftshift(masks_array)\n",
    "# print(np.fft.fftshift(masks_array).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 256, 320)\n"
     ]
    }
   ],
   "source": [
    "print(masks_array.shape)\n",
    "new_masks_file = h5py.File(\"/tmp/kellman/3d_dataset_masks_50.h5\", \"w\")\n",
    "new_masks_file['masks'] = masks_array\n",
    "new_masks_file.flush()\n",
    "new_masks_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping masks + ksp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_maps_arr = np.array(reduced_maps)\n",
    "reduced_ksp_arr = np.array(reduced_ksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8, 64, 256, 320)\n",
      "(16, 8, 64, 256, 320)\n"
     ]
    }
   ],
   "source": [
    "print(reduced_maps_arr.shape)\n",
    "print(reduced_ksp_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped_maps_filename = \"/mikQNAP/kellman/mri_data_3d_64/maps_train_64.h5\"\n",
    "!mkdir /tmp/kellman/\n",
    "cropped_maps_filename = \"/tmp/kellman/maps_train_64.h5\"\n",
    "new_maps_file = h5py.File(cropped_maps_filename, \"a\")\n",
    "new_maps_file['maps'] = reduced_maps_arr\n",
    "new_maps_file.flush()\n",
    "new_maps_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coil compression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maps']\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "cc_maps = []\n",
    "cc_ksp = []\n",
    "\n",
    "with h5py.File(cropped_maps_filename) as F:\n",
    "    print(list(F.keys()))\n",
    "    length = len(F['maps'])\n",
    "    for i in range(length):\n",
    "        print(i)\n",
    "        maps = np.array(F['maps'][i,...], dtype=np.complex)\n",
    "        ksp = reduced_ksp_arr[i,...]\n",
    "        \n",
    "        # note: these are hardcoded values that should be changed \n",
    "        ksp_center = ksp[:, 20:44, 116:140, 148:172]\n",
    "        \n",
    "        cent_k = ksp_center.reshape(8, -1)\n",
    "        U, S, V = np.linalg.svd(cent_k, full_matrices=False)\n",
    "        \n",
    "        # notes: these are hardcoded values that should be changed \n",
    "        maps_out = (np.conj(U.T) @ maps.reshape(8,-1)).reshape(8, 64, 256, 320)\n",
    "        ksp_out = (np.conj(U.T) @ ksp.reshape(8, -1)).reshape(8, 64, 256, 320)\n",
    "        cc_maps.append(maps_out)\n",
    "        cc_ksp.append(ksp_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_maps_array = np.array(cc_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8, 64, 256, 320)\n"
     ]
    }
   ],
   "source": [
    "print(reduced_maps_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_maps_filename = \"/tmp/kellman/maps_test_reduced_64.h5\"\n",
    "reduced_maps_file = h5py.File(cc_maps_filename, \"a\")\n",
    "reduced_maps_file['maps'] = reduced_maps_array\n",
    "reduced_maps_file.flush()\n",
    "reduced_maps_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_ksp_arr = np.array(cc_ksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8, 64, 256, 320)\n"
     ]
    }
   ],
   "source": [
    "print(reduced_ksp_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_arr = np.array([np.sum(np.fft.ifftshift(np.fft.ifftn(cc_ksp[i], axes=(1,2,3)),axes=(1,2,3)) * np.conj(cc_maps[i]), axis=0) for i in range(len(cc_ksp))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_filename = \"imgs_train_64\"\n",
    "new_gt_file = h5py.File(gt_filename, \"a\")\n",
    "new_gt_file['imgs'] = gt_arr\n",
    "new_gt_file.flush()\n",
    "new_gt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_map_size(maps, size):    \n",
    "    x_dim = maps.shape[1]\n",
    "    exclude = int((x_dim - size) / 2)    \n",
    "    maps_fft = np.fft.fftshift(np.fft.fft(maps, axis=1), axes=(1))\n",
    "    maps_fft_cropped = np.fft.ifftshift(maps_fft[:, exclude:x_dim-exclude, ...], axes=(1))\n",
    "    maps_comp = np.fft.ifft(maps_fft_cropped, axis=1)\n",
    "    return maps_comp\n",
    "\n",
    "def crop_ksp_size(ksp, size):\n",
    "    x_dim = ksp.shape[1]\n",
    "    exclude = int((x_dim - size) / 2)\n",
    "    \n",
    "    ksp_cropped = ksp[:, exclude:x_dim-exclude, ...]\n",
    "#     ksp_cropped_ifft = np.fft.fftshift(np.fft.ifftn(ksp_cropped, axes=(1,2,3)), axes=(1,2,3))\n",
    "    \n",
    "#     img = np.sum(ksp_cropped_ifft * np.conj(maps), axis=0)\n",
    "    return ksp_cropped\n",
    "\n",
    "# this is actually unused delete later?\n",
    "def reduce_size(maps, meas, num_vals):\n",
    "#     x_dim = maps.shape[1]\n",
    "#     exclude = int((x_dim - size) / 2)\n",
    "    \n",
    "    maps_np = cp.r2c(maps.cpu().numpy())\n",
    "    meas_np = cp.r2c(meas.cpu().numpy())\n",
    "    \n",
    "    maps_shape = (num_vals, *maps_np.shape[1:])\n",
    "    meas_shape = (num_vals, *meas_np.shape[1:])\n",
    "    \n",
    "    # these values are hardcoded in, change later!!!!!\n",
    "    meas_np_center = np.fft.fftshift(meas_np)[:, 20:44, 116:140, 148:172]\n",
    "    \n",
    "    print(meas_np_center.shape)\n",
    "    cent_k = meas_np_center.reshape(8, -1)\n",
    "    U, S, V = np.linalg.svd(cent_k, full_matrices=False)\n",
    "    U1 = U[:, :num_vals]\n",
    "    \n",
    "    meas_reshape = meas_np.reshape(8, -1)\n",
    "    maps_reshape = maps_np.reshape(8, -1)\n",
    "    \n",
    "    \n",
    "    meas_reduced_reshape = np.conj(U1.T) @ meas_reshape\n",
    "    maps_reduced_reshape = np.conj(U1.T) @ maps_reshape\n",
    "    \n",
    "    return maps_reduced_reshape.reshape(*maps_shape), meas_reduced_reshape.reshape(*meas_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
